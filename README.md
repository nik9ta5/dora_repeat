# Воспроизведение результатов статьи DoRA: Weight-Decomposed Low-Rank Adaptation 

* [Archive](https://arxiv.org/html/2402.09353v6) 
* [ICML 2024](https://openreview.net/forum?id=3d5CIRG1n2)

---
Директория `peft/` скопирована из репозитория [GitHub](https://github.com/NVlabs/DoRA)

В блокноте `indexGemma1B.ipynb` частичное воспроизведение результатов статьи. Выводы в конце блокнота.

Для тонкой настройки был выбран бенчмарк `HellaSwag`, который был взят из [LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters/tree/main/dataset)
